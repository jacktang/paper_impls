{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* https://hal.science/hal-03421252/document: From Optimality to Robustness: Dirichlet Sampling Strategies in Stochastic Bandits\n",
    "* Non-parametric algorithms for multi-armed bandits: https://theses.hal.science/tel-04070031/document \n",
    "> We propose a risk-aware algorithm for a bandit problem where the learner wants to find a safe arm according to a risk metric: the Conditional-Value-at-Risk. We also propose efficient algorithms for a problem analogous to the limit case of this setting, known as Extreme Bandits. Finally, we also adapt some of our approaches for standard variant of MAB, including one with non-stationary\n",
    "rewards and one with feedback grouped into batches of observations.\n",
    "\n",
    "https://github.com/DBaudry/Sub-Sampling-Dueling-Algorithms-Neurips20/blob/master/MAB.py"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
